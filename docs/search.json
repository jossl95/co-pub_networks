[
  {
    "objectID": "src/docs/content/process_gender.html",
    "href": "src/docs/content/process_gender.html",
    "title": "Data Preparation Gender",
    "section": "",
    "text": "# clear the global environment\nrm(list = ls())\ngc()\n\n          used (Mb) gc trigger (Mb) limit (Mb) max used (Mb)\nNcells  605062 32.4    1370858 73.3         NA   715780 38.3\nVcells 1115649  8.6    8388608 64.0      16384  2011085 15.4\n\n\n\n# load custom functions\nsource(\"src/utils/custom_functions.r\")\n\n# load and activate packages\nfpackage.check(c(\n  'tidyverse', 'readxl',  'stringr', \n  'lubridate', 'httr2', 'rvest', 'xml2',\n  \"purrr\"\n))"
  },
  {
    "objectID": "src/docs/content/process_gender.html#getting-started",
    "href": "src/docs/content/process_gender.html#getting-started",
    "title": "Data Preparation Gender",
    "section": "",
    "text": "# clear the global environment\nrm(list = ls())\ngc()\n\n          used (Mb) gc trigger (Mb) limit (Mb) max used (Mb)\nNcells  605062 32.4    1370858 73.3         NA   715780 38.3\nVcells 1115649  8.6    8388608 64.0      16384  2011085 15.4\n\n\n\n# load custom functions\nsource(\"src/utils/custom_functions.r\")\n\n# load and activate packages\nfpackage.check(c(\n  'tidyverse', 'readxl',  'stringr', \n  'lubridate', 'httr2', 'rvest', 'xml2',\n  \"purrr\"\n))"
  },
  {
    "objectID": "src/docs/content/process_gender.html#functions",
    "href": "src/docs/content/process_gender.html#functions",
    "title": "Data Preparation Gender",
    "section": "Functions",
    "text": "Functions\n\nCall Meertens Voornamen Databank\n\nis_ok = function(resp) resp_status(resp) &gt;= 200 && resp_status(resp) &lt; 300\n\nrequest_gender = function(\n    first_name,\n    base = \"https://nvb.meertens.knaw.nl/naam/is/\",\n    pause = 0.5\n  ){\n  # configure url for scraping\n  url  = paste0(base, URLencode(tolower(first_name), reserved = TRUE))\n\n  # configure user agent\n  ua = paste(\n    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 15_5)\",\n    \"AppleWebKit/537.36 (KHTML, like Gecko)\",\n    \"Chrome/129.0.0.0 Safari/537.36\"\n  )\n\n  req = request(url) |&gt;\n    req_user_agent(ua) |&gt;\n    req_timeout(30) |&gt;\n    req_headers(\n      \"Accept\" = \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n      \"Accept-Language\" = \"nl,en;q=0.8\"\n    ) |&gt;\n    # Retry on 429/5xx, and *also* on network hiccups:\n    req_retry(\n      max_tries = 4,\n      backoff = ~ runif(1, 0.5, 1.2) * (2 ^ (.x - 1)),  # jittered exponential\n      is_transient = function(resp) {\n        code &lt;- resp_status(resp)\n        isTRUE(code == 429L || (code &gt;= 500L & code &lt; 600L))\n      }\n    )\n\n  # polite pause + jitter\n  if (pause &gt; 0) Sys.sleep(pause + runif(1, 0, 0.4))\n\n  # CRITICAL: don't throw on transport errors\n  resp &lt;- tryCatch(\n    req_perform(req),\n    error = function(e) {\n      attr(e, \"nvb_url\") &lt;- url\n      e\n    }\n  )\n\n  # Return a uniform list the caller can inspect\n  if (inherits(resp, \"error\")) {\n    return(list(ok = FALSE, status = NA_integer_, url = url, resp = NULL, error = resp))\n  }\n\n  list(ok = is_ok(resp), status = resp_status(resp), url = url, resp = resp, error = NULL)\n}\n\n\n\nExtract Gender Information\n\nextract_gender_information = function(\n    resp,\n    first_name\n  ){\n  # extract all the tables on the page\n  html = read_html(resp_body_string(resp))\n  tables = html_table(html, header=TRUE)\n\n  # select the first table if a table if found\n  if (length(tables) == 0) stop(\"No tables were found\")\n  tab = tables[[1]]\n\n  # extract information from table\n  male_count = tab[1, 3] |&gt; pull()\n  male_count = ifelse(male_count == '--', 0, as.numeric(male_count))\n  female_count = tab[5, 3] |&gt; pull() \n  female_count = ifelse(female_count == '--', 0, as.numeric(female_count))\n  probability_male = male_count / (female_count + male_count) \n\n  # configure results table\n  res = tibble::tribble(\n    ~first_name, ~male_count, ~female_count, ~probability_male,\n    first_name, male_count,  female_count,  probability_male\n  )\n  return(res)\n}\n\n\n\nHelper functions\n\nsafe_extract = purrr::possibly(\n  extract_gender_information,\n  otherwise = tibble::tibble(\n    first_name       = NA_character_,\n    male_count       = NA_integer_,\n    female_count     = NA_integer_,\n    probability_male = NA_real_\n  )\n)\n\nget_gender_row = function(name, gender) {\n  # If cached, return from cache\n  if (name %in% gender$first_name) {\n    return(gender |&gt; filter(first_name == name))\n  }\n\n  r &lt;- request_gender(name)\n\n  # If transport error or HTTP not OK, surface status & keep going\n  if (!isTRUE(r$ok)) {\n    return(tibble(\n      first_name       = NA_character_,\n      male_count       = NA_integer_,\n      female_count     = NA_integer_,\n      probability_male = NA_real_\n    ))\n  }\n\n  out &lt;- safe_extract(r$resp, name) |&gt;\n    mutate(first_name = name)\n\n  out\n}\n\n\n\nPatch Difficult Names\n\npatch_gender_on_splits = function(gender){\n  # set gender cache\n  gender_cache = gender |&gt; drop_na()\n  # select authors without gender, and split their names\n  selection = gender |&gt;\n    filter(is.na(male_count)) |&gt;\n    mutate(first_name_split = str_split(first_name, ' ')) |&gt;\n    unnest_longer(first_name_split) |&gt;\n    select(first_name, first_name_split)\n\n  # get first names from selection\n  first_names = selection |&gt;\n    select(first_name_split) |&gt;\n    pull() |&gt;\n    unique()\n\n  # patch gender --------------------------------------\n  gender_patch = purrr::map_dfr(\n    first_names, get_gender_row, gender = gender_cache\n  )\n\n  # aggregate gender information\n  gender_patch = selection |&gt;\n    left_join(\n      gender_patch, \n      by=join_by(first_name_split == first_name)\n    ) |&gt;\n    drop_na() |&gt;\n    # take the average gender count and probablity\n    # for names where both splits yielded a gender\n    # result\n    group_by(first_name) |&gt;\n    summarise(\n      male_count = as.integer(mean(male_count)),\n      female_count = as.integer(mean(female_count)),\n      probability_male = mean(probability_male)\n    ) |&gt;\n    ungroup() \n\n  gender |&gt; rows_update(gender_patch)\n}\n\n\n\nClean Gender Information\n\nclean_gender = function(data){\n  gender |&gt;\n  mutate(\n    gender = ifelse(\n      probability_male &gt;= 0.5,\n      'male','female'\n    ),\n    count = ifelse(\n      gender == 'male',\n      male_count, female_count\n    ),\n    prob = ifelse(\n      gender == 'male',\n      probability_male, 1 - probability_male\n    )\n  ) |&gt;\n  select(first_name, gender, prob, count)\n}"
  },
  {
    "objectID": "src/docs/content/process_gender.html#application",
    "href": "src/docs/content/process_gender.html#application",
    "title": "Data Preparation Gender",
    "section": "Application",
    "text": "Application\n\ndir = file.path('data', 'processed')\nfile = list.files(dir, pattern = 'names.Rds')[[1]]\nnames = readRDS(file.path(dir, file))\n\nfirst_names = names |&gt;\n  distinct(first_name) |&gt;\n  filter(!is.na(first_name), first_name != \"\") |&gt;\n  pull(first_name)\n\ngender_cache = readRDS(file.path(\"data\", \"utils\", \"nvb_gender.Rds\")) |&gt; \n  # select(-status) |&gt;\n  tidyr::drop_na()\n\ngender = purrr::map_dfr(\n    first_names, \n    get_gender_row, \n    gender = gender_cache\n  ) |&gt;\n  patch_gender_on_splits() \n\nMatching, by = \"first_name\"\n\n  # |&gt;\n  # select(-status)\n\nsaveRDS(\n  gender |&gt; drop_na(),\n  file.path('data', 'utils', \"nvb_gender.Rds\")\n)\n\ngender |&gt; \n  clean_gender() |&gt;\n  fsaveRDS('gender')\n\n[1] \"SAVING: ./data/processed/20251010gender.Rds\""
  },
  {
    "objectID": "src/docs/content/process_names.html",
    "href": "src/docs/content/process_names.html",
    "title": "Data Preparation Gender",
    "section": "",
    "text": "# clear the global environment\nrm(list = ls())\ngc()\n\n          used (Mb) gc trigger (Mb) limit (Mb) max used (Mb)\nNcells  604996 32.4    1370670 73.3         NA   715780 38.3\nVcells 1114488  8.6    8388608 64.0      16384  2011085 15.4\n\n\n\nsource(\"src/utils/custom_functions.r\")\n\n# load and activate packages\nfpackage.check(c(\n  'tidyverse', 'readxl',  'stringr', \n  'lubridate'\n))"
  },
  {
    "objectID": "src/docs/content/process_names.html#getting-started",
    "href": "src/docs/content/process_names.html#getting-started",
    "title": "Data Preparation Gender",
    "section": "",
    "text": "# clear the global environment\nrm(list = ls())\ngc()\n\n          used (Mb) gc trigger (Mb) limit (Mb) max used (Mb)\nNcells  604996 32.4    1370670 73.3         NA   715780 38.3\nVcells 1114488  8.6    8388608 64.0      16384  2011085 15.4\n\n\n\nsource(\"src/utils/custom_functions.r\")\n\n# load and activate packages\nfpackage.check(c(\n  'tidyverse', 'readxl',  'stringr', \n  'lubridate'\n))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scientific Co-Publishing Networks",
    "section": "",
    "text": "Note\n\n\n\nProject Description goes here"
  },
  {
    "objectID": "src/docs/content/create_scholars.html",
    "href": "src/docs/content/create_scholars.html",
    "title": "Data Preparation Scholars",
    "section": "",
    "text": "# clear the global environment\nrm(list = ls())\ngc()\n\n          used (Mb) gc trigger (Mb) limit (Mb) max used (Mb)\nNcells  605246 32.4    1371384 73.3         NA   715780 38.3\nVcells 1121826  8.6    8388608 64.0      16384  2011085 15.4\n\n\n\n# load custom functions\nsource(\"src/utils/custom_functions.r\")\n\n# load and activate packages\nfpackage.check(c(\n  'tidyverse', 'readxl', 'renv', 'stringr', \n  'janitor', 'lubridate'\n))"
  },
  {
    "objectID": "src/docs/content/create_scholars.html#getting-started",
    "href": "src/docs/content/create_scholars.html#getting-started",
    "title": "Data Preparation Scholars",
    "section": "",
    "text": "# clear the global environment\nrm(list = ls())\ngc()\n\n          used (Mb) gc trigger (Mb) limit (Mb) max used (Mb)\nNcells  605246 32.4    1371384 73.3         NA   715780 38.3\nVcells 1121826  8.6    8388608 64.0      16384  2011085 15.4\n\n\n\n# load custom functions\nsource(\"src/utils/custom_functions.r\")\n\n# load and activate packages\nfpackage.check(c(\n  'tidyverse', 'readxl', 'renv', 'stringr', \n  'janitor', 'lubridate'\n))"
  },
  {
    "objectID": "src/docs/content/create_scholars.html#functions",
    "href": "src/docs/content/create_scholars.html#functions",
    "title": "Data Preparation Scholars",
    "section": "Functions",
    "text": "Functions\n\nLoading in Raw Data\nThis function loads in Excel files containing information on scholars working in Dutch sociology and political science departments. The data have been collected at three points in time — 19 December 2022, 19 April 2024, and 1 October 2025 — to capture changes in staff composition over time. Each Excel file includes two sheets, one for Sociologie and one for Politicologie, which are read in separately, harmonized, and then concatenated into a single dataset that combines all disciplines and time points.\n\n# define tailored functions\nread_spreadsheet = function(filepath, sheet){  \n  readxl::read_excel(filepath, sheet = sheet) \n}\n\nharmonize_columns = function(data, discipline, date){\n  data = data |&gt;\n    clean_names() |&gt;\n    mutate(\n      discipline = discipline,\n      date = date\n    ) |&gt;\n    relocate(c(discipline, date), .before = 1)\n}\n\nfread = function(\n    files, \n    source,\n    disciplines = c( \"Politicologie\", \"Sociologie\"),\n    language = 'nl'\n  ){\n  # read in both sheets from excel files\n  hold = c()\n  for (file in files){\n    filepath = file.path(source, file)\n    date = ymd(str_split(file, pattern = \"_\")[[1]][1])\n\n    # each file contains two sheets, for each discipline\n    # read in both sheets and combine these data\n    disciplines = c( \"Politicologie\", \"Sociologie\")\n    chunks = c()\n    for (discipline in disciplines){\n      chunk = read_spreadsheet(filepath, discipline) |&gt;\n        harmonize_columns(discipline, date)\n\n      chunks[[discipline]] = chunk\n    }\n\n    hold[[file]] =  bind_rows(chunks)\n  }\n\n  data = bind_rows(hold)\n\n  if (!language %in% c('nl', 'en')) stop(\"language should be nl or en\")\n  # implement rename function for english column namesac\n  \n\n  return(data)\n}\n\n\n\nFix Scholar Names\nThis step standardizes scholar names to ensure consistent matching across sources. It first normalizes name particles common in Dutch and related languages (e.g., van, de, der, ten, ’t, le, el, op den) by converting them to lowercase when they appear between spaces (e.g., “Jan van Dijk”). Next, it corrects a curated set of frequent typos and formatting inconsistencies - such as fixing misplaced or missing initials, diacritics, and misspellings (e.g., “AJGM van Montfort” to “A.J.G.M. van Montfort,” “Lea Kroner” to “Lea Kröner”). The result is a cleaned naam field with harmonized capitalization and corrected names, improving join accuracy and downstream deduplication.\n\nfix_scholar_names = function(data){\n  # fix the particles in the names\n  particles = c(\n    \"van\", \"in\",\n    \"de\", \"den\", \"der\", \"den\", \"del\",\n    \"te\", \"ten\", \"ter\", \"tes\", \"'t\",\n    \"la\", \"le\", \"les\", \"los\", \"el\", \"el-\",\n    \"op den\"\n  )\n  pattern = regex(\n    paste0(\"(?&lt;=\\\\s)(\", paste(particles, collapse = \"|\"), \")(?=\\\\s)\"),\n    ignore_case = TRUE\n  )\n\n  data |&gt;\n    mutate(\n      # replace capitalized particles\n      naam = str_replace_all(naam, pattern, ~ tolower(.x)),\n\n      # replace typos and mistakes in names\n      naam = case_when(\n        naam == \"Andrea Forstrer\"      ~ \"Andrea Forster\",\n        naam == \"AJGM van Montfort\"    ~ \"A.J.G.M. van Montfort\",\n        naam == \"FP Wagenaar\"          ~ \"F.P. Wagenaar\",\n        naam == \"JP Presley\"           ~ \"J.P. Presley\",\n        naam == \"JS Timmer\"            ~ \"J.S. Timmer\",\n        naam == \"ilya Lavrov\"          ~ \"Ilya Lavrov\",\n        naam == \"p. Vila Soler\"        ~ \"P. Vila Soler\",\n        naam == \"Z Dong\"               ~ \"Z. Dong\",\n        naam == \"Renae  Loh\"           ~ \"Renae Loh\",\n        naam == \"Paulina Pankowski\"    ~ \"Paulina Pankowska\",\n        naam == \"M.M Cuperus\"          ~ \"M.M. Cuperus\",\n        naam == \"Lea Kroner\"           ~ \"Lea Kröner\",\n        naam == \"L Slot\"               ~ \"L. Slot\",\n        naam == \"Jan Willen Duyvendak\" ~ \"Jan Willem Duyvendak\",\n        .default = naam\n      )\n    )\n}\n\n\n\nFixing Google Scholar ID\nThis step propagates known Google Scholar IDs across time for the same person. The data are first ordered by naam and date, then grouped by naam so that each individual’s records form a sequence. Within each group, missing values in google_scholar_id are filled using the nearest available value, with the fill direction controlled by the .direction argument (default “updown” fills forward and backward; alternatives like “down” or “up” restrict the fill to one direction). Groups are then ungrouped and the dataset is tidied by universiteit and date. This reduces missing IDs while ensuring values never leak across different people; it assumes that identical names refer to the same scholar, so remaining homonyms should be checked upstream.\n\nfix_google_scholar_id = function(data, .direction='updown'){\n  data |&gt;\n    arrange(naam, date) |&gt;\n    group_by(naam) |&gt;\n    # fill missing values with available information\n    fill(google_scholar_id, .direction = .direction) |&gt;  \n    ungroup() |&gt;\n    arrange(universiteit, date)\n}\n\n\n\nFixing Email Addresses\nThis step standardizes and completes the email address information for each scholar. It first applies a practical, case-insensitive regular expression that captures valid email formats, including subdomains, to extract clean addresses from the email_adres field. All extracted emails are then converted to lowercase to ensure consistency. Next, the data are grouped by universiteit and naam, and missing email values are filled using the nearest available information within each group (by default in both directions, controlled by the .direction argument). Finally, the dataset is ungrouped and ordered by universiteit and date, resulting in a harmonized and more complete set of email addresses that align across time points for the same scholar\n\nfix_email_adresses = function(data, .direction = \"updown\"){\n  # practical email regex (case-insensitive), supports subdomains\n  email_pattern = regex(\n    \"\\\\b[[:alnum:]._%+-]+@[[:alnum:]-]+(?:\\\\.[[:alnum:]-]+)+\\\\b\", \n    ignore_case = TRUE\n  )\n\n  # clean email variable\n  data |&gt;\n    mutate(\n      email_adres = str_extract(\n        email_adres, email_pattern\n        ) |&gt; tolower()\n    ) |&gt;\n    group_by(universiteit, naam) |&gt;\n    # fill \n    fill(email_adres, .direction = \"updown\") |&gt;\n    ungroup()|&gt;\n    arrange(universiteit, date)\n}\n\n\n\nFixing Universities\nThis step harmonizes university affiliations and adds a canonical code alongside the raw label. It first splits multi-valued entries in universiteit (e.g., “UU / UvA”) into separate rows, then trims and normalizes each label. Using a case-insensitive pattern, it maps recognized names/abbreviations to a standard set (EUR, RU, RUG, UU, VU, UvA, UvT, Leiden). If a canonical code is still missing, it infers the affiliation from the email domain (e.g., …@essb.eur.nl -&gt; EUR, …@vu.nl -&gt; VU, …@uva.nl -&gt; UvA, etc.). After removing duplicates, affiliations are re-aggregated per person and date into a list column university, joined back to the original data, and positioned next to universiteit. The result is a consistent, machine-readable university code that supports reliable grouping, filtering, and longitudinal comparison.\n\nclean_universities = function(data){\n  universities = c(\"EUR\", \"RU\", \"RUG\", \"UU\", \"VU\", \"UvA\", \"UvT\", \"LU\")\n  pat   = regex(\"\\\\b(EUR|RU|RUG|UU|VU|UvA|UvT|Leiden)\\\\b\", ignore_case = TRUE)\n  canon = setNames(universities, universities)\n\n  # clean universities\n  uni = data |&gt;\n    # split university strings on '\\s' , '/', '\\.', and '?'\n    mutate(\n      universiteit = str_split(universiteit, \"/+|\\\\?+\"),\n    ) |&gt;\n    unnest_longer(universiteit) |&gt;\n    # clean the university labels\n    mutate(\n      universiteit = str_replace(str_squish(universiteit), 'Leiden uni', 'Leiden'),\n      university = str_replace(universiteit, pat, \\(m) canon[str_to_lower(m)]),\n      universiteit = case_when(\n        (is.na(university) & str_detect(email_adres, 'essb.eur.nl')) ~ 'EUR',\n        (is.na(university) & str_detect(email_adres, 'vu.nl'))  ~ 'VU',\n        (is.na(university) & str_detect(email_adres, 'uva.nl'))  ~  'UVA',\n        (is.na(university) & str_detect(email_adres, 'leidenuni'))  ~  'Leiden',\n        (is.na(university) & str_detect(email_adres, 'ru.nl'))  ~  'RU',\n        (is.na(university) & str_detect(email_adres, 'rug.nl'))  ~  'RUG',\n        (is.na(university) & str_detect(email_adres, 'tilburguni'))  ~  'UvT',\n        (is.na(university) & str_detect(email_adres, 'uu.nl'))  ~  'UU',\n        .default = university\n      ),\n      university = ifelse(\"\" == university, NA_character_, university)\n    ) |&gt;\n    distinct(.keep_all=TRUE) |&gt;\n    group_by(naam, date) |&gt; \n    summarise(university = list(unlist(university))) |&gt;\n    ungroup()\n\n  data |&gt;\n    left_join(uni) |&gt;\n    relocate(university, .after=universiteit)\n}\n\n\n\nClean functie\nThis step parses free-text job titles in functie into a set of consistent role flags. It first keeps only date, naam, and functie, then lowercases functie for keyword matching. Using targeted patterns in Dutch and English, it creates boolean indicators for common categories:\n\nvisiting (e.g., gast, visit),\nexternal (buiten, external),\nprofessor (incl. typos like proffessor),\nassociate professor (hoofddocent, associate, uhd),\nassistant professor (universitair docent, assistant),\npostdoc (postdoc, doctoral),\nlecturer (docent, lecturer, teacher),\nresearcher (onderzoeker, research),\nPhD (phd, promovend),\nsenior/junior,\nemeritus (professor + emiri) or endowed (professor + bijzon),\nfellow,\nand a broad staff (e.g., advisor, secretary, assistent, medewerker, manager, coordinator, director/directeur).\n\nTo avoid double counting, several flags are explicitly set to FALSE when a more specific academic rank applies (e.g., assistant/associate/full professor precedence over lecturer/researcher/staff). Missing titles propagate as NA in the corresponding flags. The result is a tidy, machine-readable set of role indicators that standardizes heterogeneous job titles for downstream classification and analysis.\n\nparse_job_titles = function(data){\n  data |&gt;\n    select(date, naam, functie) |&gt;\n    mutate(\n      is_visiting = case_when(\n        str_detect(str_to_lower(functie), 'gast') ~ TRUE,\n        str_detect(str_to_lower(functie), 'visit') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_external = case_when(\n        str_detect(str_to_lower(functie), 'external') ~ TRUE,\n        str_detect(str_to_lower(functie), 'buiten') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_associate_professor = case_when(\n        str_detect(str_to_lower(functie), 'hoofddocent') ~ TRUE,\n        str_detect(str_to_lower(functie), 'associate ') ~ TRUE,\n        str_detect(str_to_lower(functie), 'uhd') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_assistant_professor = case_when(\n        is_associate_professor ~ FALSE,\n        str_detect(str_to_lower(functie), 'universitair docent') ~ TRUE,\n        str_detect(str_to_lower(functie), 'assistant ') ~ TRUE, \n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_postdoc = case_when(\n        str_detect(str_to_lower(functie), 'postdoc') ~ TRUE,\n        str_detect(str_to_lower(functie), 'doctoral') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_senior = case_when(\n        str_detect(str_to_lower(functie), 'senior') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_junior = case_when(\n        str_detect(str_to_lower(functie), 'junior') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_lecturer = case_when(\n        is_associate_professor ~ FALSE, \n        is_assistant_professor ~ FALSE, \n        str_detect(str_to_lower(functie), 'lecturer') ~ TRUE,\n        str_detect(str_to_lower(functie), 'docent') ~ TRUE,\n        str_detect(str_to_lower(functie), 'teacher') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_researcher = case_when(\n        is_associate_professor ~ FALSE, \n        is_assistant_professor ~ FALSE,\n        is_postdoc ~ FALSE, \n        str_detect(str_to_lower(functie), 'onderzoeker') ~ TRUE,\n        str_detect(str_to_lower(functie), 'research') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_phd = case_when(\n        str_detect(str_to_lower(functie), 'phd') ~ TRUE,\n        str_detect(str_to_lower(functie), 'promovend') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_professor = case_when(\n        is_associate_professor ~ FALSE, \n        is_assistant_professor ~ FALSE,\n        is_postdoc ~ FALSE, \n        str_detect(str_to_lower(functie), 'hoogleraar') ~ TRUE,\n        str_detect(str_to_lower(functie), 'professor') ~ TRUE,\n        str_detect(str_to_lower(functie), 'proffessor') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_emeritus = case_when(\n        is_professor & str_detect(str_to_lower(functie), 'emiri') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_endowed = case_when(\n        is_professor & str_detect(str_to_lower(functie), 'bijzon') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      ),\n      is_staff = case_when(\n        # make sure that people with other positions are not falsely\n        # been configured to be a staff member.\n        is_associate_professor ~ FALSE, \n        is_assistant_professor ~ FALSE,\n        is_lecturer ~ FALSE,\n        is_postdoc ~ FALSE,\n        is_professor ~ FALSE,\n        # staff members have wildly varying job titles.\n        str_detect(str_to_lower(functie), 'advisor') ~ TRUE,\n        str_detect(str_to_lower(functie), 'secretary') ~ TRUE,\n        str_detect(str_to_lower(functie), 'assistent') ~ TRUE,\n        str_detect(str_to_lower(functie), 'medewerk') ~ TRUE,\n        str_detect(str_to_lower(functie), 'market') ~ TRUE,\n        str_detect(str_to_lower(functie), 'managing') ~ TRUE,\n        str_detect(str_to_lower(functie), 'manager') ~ TRUE,\n        str_detect(str_to_lower(functie), 'coordinator') ~ TRUE,\n        str_detect(str_to_lower(functie), 'director') ~ TRUE,\n        str_detect(str_to_lower(functie), 'directeur') ~ TRUE,\n      ),\n      is_fellow = case_when(\n        str_detect(str_to_lower(functie), 'fellow') ~ TRUE,\n        is.na(functie) ~ NA,\n        .default = FALSE\n      )\n    )\n}\n\nBuilding on the role flags derived in Clean functie, this step converts those boolean indicators into human-readable position labels and, optionally, a compact string that also captures distinctions.\n\nconstruct_positions() maps the mutually exclusive academic roles to a canonical position (e.g., Full Professor, Associate Professor, Assistant Professor, Postdoctoral Researcher, PhD Candidate, Lecturer, Researcher, Staff) while separately flagging distinctions as short text labels: Visiting, External, Senior, Junior, Emeritus, Endowed, and Fellow.\n\nAfter creating these columns, it drops the original is_ flags and constructs position2 by uniting any present distinctions (from visiting through fellow) into a single, comma-separated string (leaving the per-column distinction flags intact for auditing).\n\nclean_functie() then orchestrates the full cleaning. It first runs parse_job_titles() to produce the role flags, passes the result through construct_positions(), and finally writes the output back into the original data:\n.what = \"complete\" (default) sets functie to the canonical position (rank only).\n.what = \"simplified\" sets functie to position2, which includes any distinctions (e.g., Assistant Professor, Visiting; Fellow).\n\nThe result is a consistent functie column suitable either for strict rank analyses (complete) or for descriptive reporting that preserves visiting/external/fellow/etc. qualifiers (simplified).\n\nconstruct_positions = function(data) {\n  data |&gt;\n    mutate(\n      # make flags for people with one of the following distinctions\n      visiting = ifelse(is_visiting, 'Visiting', NA_character_),\n      external = ifelse(is_external, 'External', NA_character_),\n      senior = ifelse(is_senior, 'Senior', NA_character_),\n      junior = ifelse(is_junior, 'Junior', NA_character_),\n      emeritus = ifelse(is_emeritus, 'Emeritus', NA_character_),\n      endowed = ifelse(is_endowed, 'Endowed', NA_character_),\n      # create a basic positions variable, excluding distinctions\n      position = case_when(\n        is_professor ~ \"Full Professor\",\n        is_associate_professor ~ \"Associate Professor\",\n        is_assistant_professor ~ \"Assistant Professor\",\n        is_postdoc ~ \"Postdoctoral Researcher\",\n        is_phd ~ \"PhD Candidate\",\n        is_lecturer ~ \"Lecturer\",\n        is_researcher ~ \"Researcher\",\n        is_staff ~ \"Staff\",\n        .default = NA_character_\n      ),\n      fellow = ifelse(is_fellow, 'Fellow', NA_character_)\n    ) |&gt;\n    select(!starts_with('is_')) |&gt;\n    unite('position2', visiting:fellow, na.rm=TRUE, remove=FALSE)\n}\n\nclean_functie = function(data, .what='complete'){\n  test = data |&gt; \n    parse_job_titles() |&gt;\n    construct_positions()\n\n  if (.what == 'complete'){\n    data['functie'] = test$position\n  } else if (.what == 'simplified'){\n    data['functie'] = test$position2\n  }\n\n  return(data)\n}"
  },
  {
    "objectID": "src/docs/content/create_scholars.html#execution",
    "href": "src/docs/content/create_scholars.html#execution",
    "title": "Data Preparation Scholars",
    "section": "Execution",
    "text": "Execution\n\n# identified scholarid files\nsource = file.path(\"data\", \"raw_data\")\nfiles = list.files(source, pattern = \"scholarid.xlsx\")\n\n# load and process data\ndata = fread(files, source) |&gt; \n  fix_scholar_names() |&gt;\n  clean_universities() |&gt;\n  fix_email_adresses() |&gt;\n  fix_google_scholar_id() |&gt;\n  select(-specialisatie, -notitie, -additional, -checked) |&gt;\n  arrange(discipline, date, naam, university) |&gt;\n  clean_functie()\n\n`summarise()` has grouped output by 'naam'. You can override using the\n`.groups` argument.\nJoining with `by = join_by(date, naam)`\n\n# save data\nfsave(data, 'scholarid')\n\n[1] \"SAVING: ./data/processed/20251010scholarid\""
  },
  {
    "objectID": "src/docs/content/process_names.html#functions",
    "href": "src/docs/content/process_names.html#functions",
    "title": "Data Preparation Gender",
    "section": "Functions",
    "text": "Functions\n\nParse Names\n\nparse_names = function(names){\n  particles &lt;- c(\n    \"de\",\"den\",\"der\",\"het\",\"te\",\"ten\",\"ter\",\n    \"van\",\"van de\",\"van den\",\"van der\",\"van 't\",\"van ’t\",\n    \"'t\",\"’t\",\n    \"von\",\"von der\",\"von den\",\n    \"la\",\"le\",\"du\",\"del\",\"della\",\"di\",\"da\",\"dos\",\"das\",\"de la\",\"de los\",\"de las\",\n    \"zu\",\"zum\",\"zur\"\n  )\n\n  # Normalization helper for matching\n  .normalize &lt;- function(x) {\n    x |&gt;\n      str_squish() |&gt;\n      str_replace_all(\"’\", \"'\") |&gt;\n      str_to_lower()\n    }\n\n  p_norm &lt;- .normalize(particles)\n\n  names |&gt;\n    mutate(\n      tokens_raw = str_split(naam, \"\\\\s+\"),\n      tokens_norm = map(tokens_raw, ~ .normalize(.x)),\n      n = map_int(tokens_raw, length),\n\n      # find the longest particle match immediately before the final token\n        particle_idx = map2_int(tokens_norm, n, function(tok, n_tok) {\n          if (n_tok &lt; 2) return(NA_integer_)\n          # check 3, 2, 1-token particles that end at position n_tok-1\n          for (k in 3:1) {\n            start &lt;- n_tok - k\n            end   &lt;- n_tok - 1\n            if (start &gt;= 1) {\n              cand &lt;- paste(tok[start:end], collapse = \" \")\n              if (cand %in% p_norm) return(start)\n            }\n          }\n          NA_integer_\n        }),\n\n        has_particle = !is.na(particle_idx),\n\n        first_name = pmap_chr(\n          list(tokens_raw, particle_idx, n),\n          function(tok, p_i, n_tok) {\n            end_giv &lt;- if (is.na(p_i)) n_tok - 1 else p_i - 1\n            if (end_giv &lt;= 0) tok[1] else paste(tok[seq_len(end_giv)], collapse = \" \")\n          }\n        ),\n\n        particle = pmap_chr(\n          list(tokens_raw, tokens_norm, particle_idx, n),\n          function(tok_raw, tok_norm, p_i, n_tok) {\n            if (is.na(p_i)) return(NA_character_)\n            # output particle in lowercase, canonicalised apostrophes\n            out &lt;- paste(tok_norm[p_i:(n_tok-1)], collapse = \" \")\n            out\n          }\n        ),\n\n        last_name = pmap_chr(\n          list(tokens_raw, n),\n          function(tok, n_tok) tok[n_tok]\n        )\n    ) |&gt;\n    select(naam, first_name, particle, last_name)\n}\n\n\n\nExtract Initials\n\nextract_initials = function(names){\n  names |&gt;\n    mutate(\n      initials = str_extract(\n          naam, \n          \"^((?:\\\\p{Lu}{1,2}\\\\.)+(?:-\\\\p{Lu}{1,2}\\\\.)*)(?=\\\\s)\"\n        ),\n      first_name = ifelse(is.na(initials), first_name, NA_character_)) |&gt;\n    relocate(initials, .after=naam)\n}\n\n\n\nPatch Names\n\npatch_names = function(names){\n  # read in dataset with corrections for name information\n  corrections = readRDS(file.path('data', 'utils', 'name_corrections.Rds'))\n\n  names |&gt; rows_update(corrections, by='naam', unmatched='ignore')\n}\n\n\nreadRDS(file.path('data', 'utils', 'name_corrections.Rds')) |&gt; head()\n\n# A tibble: 6 × 4\n  naam                         first_name particle last_name          \n  &lt;chr&gt;                        &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;              \n1 Marjolein Broese van Groenou Marjolein  &lt;NA&gt;     Broese-van Groenou \n2 Albornoz Barra Gonzalo       Alborno    &lt;NA&gt;     Barra Gonzalo      \n3 Amina op de Weegh            Amina      op de    Weegh              \n4 Amina Op de Weegh            Amina      Op de    Weegh              \n5 Ana Maria Torres Chedraui    Ana Maria  &lt;NA&gt;     Torres Chedraui    \n6 Ana Mishkovska Kajevska      Ana        &lt;NA&gt;     Mishkovska Kajevska\n\n\n\n\nExtract Maiden Name\n\nextract_maiden_name = function(names){\n  # split last names\n  last_name_splits = str_split(names$last_name, '-', simplify = TRUE)\n\n  # add splits to names dataframe\n  names['last_name'] = last_name_splits[,1]\n  names['maiden_name'] = ifelse(\n    last_name_splits[,2] == '',\n    NA_character_,\n    last_name_splits[,2]\n  )\n\n  return(names)\n}"
  },
  {
    "objectID": "src/docs/content/process_names.html#application",
    "href": "src/docs/content/process_names.html#application",
    "title": "Data Preparation Gender",
    "section": "Application",
    "text": "Application\n\n# load data \ndir = file.path(\"data\", \"processed\")\nfile = list.files(dir, pattern = \"scholarid.Rds\", full.names = TRUE)\n\ndata = freadRDS(file) \n\nnames = data |&gt;\n  select(naam) |&gt;\n  arrange(naam) |&gt;\n  distinct() |&gt;\n  drop_na() |&gt;\n  parse_names() |&gt;\n  extract_initials() |&gt;\n  patch_names() |&gt;\n  extract_maiden_name()\n\nfsaveRDS(\n  names, \n  'names'\n)\n\n[1] \"SAVING: ./data/processed/20251010names.Rds\""
  }
]